import pandas as pd
import numpy as np
import os
import warnings
warnings.filterwarnings("ignore")


import pandas as pd

# Question: Create a DataFrame from the dictionary {"Name": ["Alice", "Bob"], "Age": [25, 30]}.
data = {"Name": ["Alice", "Bob"], "Age": [25, 30]}
df = pd.DataFrame(data)
print("DataFrame created from dictionary:\n", df)



# Question: Check for missing values in the DataFrame.
df_missing = pd.DataFrame({"Name": ["Alice", None, "Charlie"], "Age": [25, 30, None]})
print("Original DataFrame:\n", df_missing)
print("\nMissing values in the DataFrame:\n", df_missing.isnull())
print("\nTotal missing values per column:\n", df_missing.isnull().sum())



# Question: Drop rows containing missing values.
df_dropped = df_missing.dropna()
print("DataFrame after dropping missing values:\n", df_dropped)



# Question: Fill missing values in the "Age" column with the mean.
df_missing["Age"].fillna(df_missing["Age"].mean(), inplace=True)
print("DataFrame after filling missing values with the mean:\n", df_missing)



# Question: Select the "Name" column from the DataFrame.
selected_column = df_missing["Name"]
print("Selected column (Name):\n", selected_column)



# Question: Select rows where Age > 25.
filtered_rows = df_missing[df_missing["Age"] > 25]
print("Rows where Age > 25:\n", filtered_rows)



# Question: Sort the DataFrame by "Age" in ascending order.
sorted_df = df_missing.sort_values(by="Age")
print("DataFrame sorted by Age:\n", sorted_df)



# Question: Reset the index of the sorted DataFrame.
reset_index_df = sorted_df.reset_index(drop=True)
print("DataFrame after resetting index:\n", reset_index_df)



# Question: Add 5 to each value in the "Age" column.
df_missing["Age"] = df_missing["Age"].apply(lambda x: x + 5)
print("DataFrame after applying custom function to Age:\n", df_missing)



# Question: Group by "Name" and calculate the mean Age.
data = {"Name": ["Alice", "Bob", "Alice", "Charlie"], "Score": [85, 92, 78, 90]}
df = pd.DataFrame(data)
grouped_mean = df.groupby("Name")["Score"].mean()
print("Grouped DataFrame with mean Score:\n", grouped_mean)



# Question: Merge df1 and df2 based on the "ID" column.
df1 = pd.DataFrame({"ID": [1, 2], "Name": ["Alice", "Bob"]})
df2 = pd.DataFrame({"ID": [1, 2], "Score": [85, 92]})
merged_df = pd.merge(df1, df2, on="ID")
print("Merged DataFrame:\n", merged_df)



# Question: Concatenate df1 and df2 along rows.
concat_df = pd.concat([df1, df2], axis=0, ignore_index=True)
print("Concatenated DataFrame:\n", concat_df)



# Question: Get unique values from the "Name" column.
unique_names = df["Name"].unique()
print("Unique names in the Name column:\n", unique_names)



# Question: Remove duplicate rows from the DataFrame.
df = pd.DataFrame({"Name": ["Alice", "Bob", "Alice"], "Score": [85, 92, 85]})
print("Original DataFrame:\n", df)
df_no_duplicates = df.drop_duplicates()
print("\nDataFrame after dropping duplicates:\n", df_no_duplicates)



import pandas as pd

# Question: Create a pivot table with the sum and mean of "Score" grouped by "Name" and "Subject".
data = {
    "Name": ["Alice", "Bob", "Alice", "Charlie", "Bob", "Charlie"],
    "Subject": ["Math", "Math", "Science", "Math", "Science", "Science"],
    "Score": [85, 90, 78, 88, 92, 80],
}
df = pd.DataFrame(data)

# Pivot table with multiple aggregations
pivot_table = pd.pivot_table(df, values="Score", index="Name", columns="Subject", aggfunc=["sum", "mean"])
pivot_table



# Question: Perform a left join and replace missing "Score" with 0.
df1 = pd.DataFrame({"ID": [1, 2, 3], "Name": ["Alice", "Bob", "Charlie"]})
df2 = pd.DataFrame({"ID": [1, 2], "Score": [85, 92]})

# Left join and filling missing values
merged_df = pd.merge(df1, df2, on="ID", how="left")
merged_df["Score"].fillna(0, inplace=True)
merged_df



# Question: Add a column showing the normalized Score within each Subject group.
df["Normalized_Score"] = df.groupby("Subject")["Score"].transform(lambda x: (x - x.mean()) / x.std())
df



# Question: Reshape the DataFrame to long format using melt, showing 'Subject' as a variable.
melted_df = pd.melt(df, id_vars=["Name"], value_vars=["Subject", "Score"])
melted_df



# Question: Rank the scores within each subject in descending order.
df["Rank"] = df.groupby("Subject")["Score"].rank(ascending=False)
print("DataFrame with ranks by Subject:\n", df)



# Question: Filter rows where the "Name" contains the substring "li".
filtered_df = df[df["Name"].str.contains("li", case=False, regex=True)]
print("Filtered DataFrame where Name contains 'li':\n", filtered_df)



# Question: Add a column showing cumulative sum of scores within each Subject group.
df["Cumulative_Sum"] = df.groupby("Subject")["Score"].cumsum()
print("DataFrame with cumulative sum by Subject:\n", df)



# Question: Identify and remove outliers using the IQR method.
Q1 = df["Score"].quantile(0.25)
Q3 = df["Score"].quantile(0.75)
IQR = Q3 - Q1

# Define outlier boundaries
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Filter out outliers
no_outliers_df = df[(df["Score"] >= lower_bound) & (df["Score"] <= upper_bound)]
print("DataFrame after removing outliers:\n", no_outliers_df)



# Question: Create a lag and lead column for scores within each Subject.
df["Lag_Score"] = df.groupby("Subject")["Score"].shift(1)
df["Lead_Score"] = df.groupby("Subject")["Score"].shift(-1)
print("DataFrame with Lag and Lead columns:\n", df)



# Question: Resample a time series DataFrame to calculate monthly averages.
time_data = {
    "Date": pd.date_range("2024-01-01", periods=12, freq="D"),
    "Value": [10, 15, 8, 20, 25, 12, 14, 9, 30, 35, 18, 22],
}
time_df = pd.DataFrame(time_data)
time_df.set_index("Date", inplace=True)

# Resample to monthly frequency and calculate mean
monthly_avg = time_df.resample("M").mean()
print("Monthly average values:\n", monthly_avg)



import pandas as pd

# Question: Calculate a 3-day rolling average of scores.
data = {
    "Date": pd.date_range(start="2024-01-01", periods=10),
    "Score": [10, 12, 15, 20, 18, 25, 22, 30, 35, 40],
}
df = pd.DataFrame(data)

# Calculate rolling mean with a window size of 3
df["3-day Rolling Average"] = df["Score"].rolling(window=3).mean()
df



# Question: Create a column that shows the difference between the current and previous row's score.
df["Score Difference"] = df["Score"].diff()
print("DataFrame with Score Difference:\n", df)



# Question: Pivot the DataFrame with multiple index levels.
data = {
    "Year": [2021, 2021, 2022, 2022],
    "Quarter": ["Q1", "Q2", "Q1", "Q2"],
    "Revenue": [200, 250, 300, 350],
    "Profit": [50, 70, 100, 120],
}
df = pd.DataFrame(data)

# Pivot the DataFrame
pivoted_df = df.pivot(index="Year", columns="Quarter", values=["Revenue", "Profit"])
print("Pivoted DataFrame:\n", pivoted_df)



# Question: Apply a function to calculate revenue-to-profit ratio for each row.
df["Revenue_to_Profit_Ratio"] = df.apply(lambda x: x["Revenue"] / x["Profit"], axis=1)
print("DataFrame with Revenue-to-Profit Ratio:\n", df)



# Question: Resample the time series data to weekly frequency and forward fill missing values.
time_data = {
    "Date": pd.date_range("2024-01-01", periods=10, freq="D"),
    "Value": [100, 200, 300, None, 500, None, 700, None, 900, 1000],
}
time_df = pd.DataFrame(time_data)
time_df.set_index("Date", inplace=True)

# Resample to weekly and fill missing values
resampled_df = time_df.resample("W").mean().fillna(method="ffill")
print("Resampled DataFrame with weekly average and missing values filled:\n", resampled_df)



# Question: Create a cross-tabulation of the number of employees by department and gender.
data = {
    "Department": ["Sales", "Sales", "HR", "HR", "IT", "IT"],
    "Gender": ["Male", "Female", "Female", "Male", "Male", "Female"],
}
df = pd.DataFrame(data)

# Create cross-tabulation
cross_tab = pd.crosstab(df["Department"], df["Gender"])
print("Cross-tabulation of departments and genders:\n", cross_tab)



# Question: Calculate the percentage contribution of each department to the total count.
department_counts = df["Department"].value_counts(normalize=True) * 100
print("Percentage contribution of each department:\n", department_counts)



# Question: Merge two DataFrames with different key columns.
df1 = pd.DataFrame({"Employee_ID": [1, 2, 3], "Name": ["Alice", "Bob", "Charlie"]})
df2 = pd.DataFrame({"Emp_ID": [1, 2, 4], "Salary": [50000, 60000, 70000]})

# Merge with different keys
merged_df = pd.merge(df1, df2, left_on="Employee_ID", right_on="Emp_ID", how="outer")
print("Merged DataFrame with different keys:\n", merged_df)



# Question: Rank employees based on Salary and Department in descending order.
df_salary = pd.DataFrame({
    "Employee": ["Alice", "Bob", "Charlie", "David"],
    "Department": ["Sales", "IT", "Sales", "HR"],
    "Salary": [50000, 60000, 55000, 52000],
})

# Ranking based on Salary and Department
df_salary["Rank"] = df_salary.groupby("Department")["Salary"].rank(ascending=False)
print("DataFrame with multi-column ranking:\n", df_salary)



# Question: Detect duplicated rows and count them.
df_duplicates = pd.DataFrame({"Name": ["Alice", "Bob", "Alice", "Charlie"], "Score": [85, 92, 85, 90]})

# Detect duplicates
duplicate_rows = df_duplicates[df_duplicates.duplicated()]
print("Duplicated rows:\n", duplicate_rows)
print("\nTotal number of duplicate rows:", duplicate_rows.shape[0])



import pandas as pd

# Question: Group by "Department" and calculate total salary only for employees with salaries > 50,000.
data = {
    "Employee": ["Alice", "Bob", "Charlie", "David", "Eve"],
    "Department": ["Sales", "IT", "Sales", "HR", "IT"],
    "Salary": [45000, 60000, 55000, 48000, 70000],
}
df = pd.DataFrame(data)

# Conditional aggregation
grouped_sum = df.groupby("Department").apply(lambda x: x[x["Salary"] > 50000]["Salary"].sum())
print("Total salary for employees with salaries > 50,000 by department:\n", grouped_sum)



# Question: Set "Department" and "Employee" as multi-index and display the DataFrame.
multi_index_df = df.set_index(["Department", "Employee"])
print("Multi-indexed DataFrame:\n", multi_index_df)



# Question: Unstack the multi-index DataFrame to bring "Employee" as columns.
unstacked_df = multi_index_df.unstack(level=1)
print("Unstacked DataFrame:\n", unstacked_df)



# Question: Fill missing values in the salary column using linear interpolation.
df_missing = pd.DataFrame({"Employee": ["Alice", "Bob", "Charlie"], "Salary": [45000, None, 55000]})
df_missing["Salary"] = df_missing["Salary"].interpolate(method="linear")
print("DataFrame after linear interpolation:\n", df_missing)



# Question: Bin salaries into categories like "Low", "Medium", and "High".
bins = [0, 50000, 60000, 80000]
labels = ["Low", "Medium", "High"]
df["Salary_Category"] = pd.cut(df["Salary"], bins=bins, labels=labels)
print("DataFrame with salary categories:\n", df)



import numpy as np

# Question: Create a column that marks employees as "Senior" if their salary > 60,000, otherwise "Junior".
df["Position"] = np.where(df["Salary"] > 60000, "Senior", "Junior")
print("DataFrame with Position column:\n", df)



from scipy.stats import zscore

# Question: Detect rows where the salary is an outlier using z-score.
df["Z-Score"] = zscore(df["Salary"])
outliers_df = df[df["Z-Score"].abs() > 2]
print("Outliers in the DataFrame:\n", outliers_df)



# Question: Add an expanding sum column for salaries.
df["Expanding_Sum"] = df["Salary"].expanding().sum()
print("DataFrame with expanding sum:\n", df)



# Question: Convert the DataFrame into a long format using stack().
stacked = df.set_index(["Department", "Employee"]).stack()
print("Stacked DataFrame (long format):\n", stacked)



# Question: Create a lagged feature for the "Value" column to predict the next day's value.
time_series_data = pd.DataFrame({"Date": pd.date_range("2024-01-01", periods=5), "Value": [100, 200, 300, 400, 500]})
time_series_data["Previous_Day_Value"] = time_series_data["Value"].shift(1)
print("Time series data with lagged feature:\n", time_series_data)



# Question: Concatenate two DataFrames with different columns and fill missing values with 0.
df1 = pd.DataFrame({"A": [1, 2], "B": [3, 4]})
df2 = pd.DataFrame({"B": [5, 6], "C": [7, 8]})

# Concatenate with axis=0 (rows)
concat_df = pd.concat([df1, df2], axis=0, sort=False).fillna(0)
print("Concatenated DataFrame:\n", concat_df)



# Question: Check if two DataFrames are equal.
df_a = pd.DataFrame({"X": [1, 2, 3], "Y": [4, 5, 6]})
df_b = pd.DataFrame({"X": [1, 2, 3], "Y": [4, 5, 6]})
are_equal = df_a.equals(df_b)
print("Are the two DataFrames equal?:", are_equal)
















