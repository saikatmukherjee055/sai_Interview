# Problem: Filter rows where Age is greater than 24 and Gender is 'Male'.

import pandas as pd

# Create the initial DataFrame
data = {
    'Name': ['John', 'Alice', 'Bob', 'Eve'],
    'Age': [25, 30, 22, 27],
    'City': ['New York', 'Los Angeles', 'Chicago', 'Houston'],
    'Gender': ['Male', 'Female', 'Male', 'Female']
}

df = pd.DataFrame(data)

# Filter rows where Age > 24 and Gender == 'Male'
filtered_df = df[(df['Age'] > 24) & (df['Gender'] == 'Male')]

# Output the result
print("Filtered rows where Age > 24 and Gender == 'Male':")
filtered_df



# Problem: Add a new column 'Category' to the DataFrame. Assign:
# - 'Senior' if Age >= 30
# - 'Adult' if 24 <= Age < 30
# - 'Young' otherwise

# Add a new column 'Category' based on the Age column
df['Category'] = df['Age'].apply(
    lambda x: 'Senior' if x >= 30 else 'Adult' if 24 <= x < 30 else 'Young'
)

# Output the updated DataFrame
print("DataFrame after adding the 'Category' column:")
df



# Problem: Calculate the average 'Age' for each 'Gender'.

# Group by Gender and calculate the mean Age
avg_age_by_gender = df.groupby('Gender')['Age'].mean()

# Output the result
print("Average Age by Gender:")
print(avg_age_by_gender)



# Problem: Sort the DataFrame by 'Category' (ascending) and 'Age' (descending).

# Sort by 'Category' and 'Age'
sorted_df = df.sort_values(by=['Category', 'Age'], ascending=[True, False])

# Output the sorted DataFrame
print("DataFrame sorted by 'Category' and 'Age':")
print(sorted_df)



# Problem: From the DataFrame, find the top 2 oldest people in each Gender group.

import pandas as pd

# Create the initial DataFrame
data = {
    'Name': ['John', 'Alice', 'Bob', 'Eve', 'Michael', 'Sophia'],
    'Age': [25, 30, 22, 27, 35, 29],
    'City': ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Seattle', 'Austin'],
    'Gender': ['Male', 'Female', 'Male', 'Female', 'Male', 'Female']
}

df = pd.DataFrame(data)

# Find the top 2 oldest people in each Gender group
top_n_by_gender = df.sort_values(by='Age', ascending=False).groupby('Gender').head(2)

# Output the result
print("Top 2 oldest people in each Gender group:")
top_n_by_gender



# Problem: Add a new column that calculates the cumulative sum of 'Age' for each Gender.

# Calculate the cumulative sum of Age within each Gender group
df['Cumulative_Age'] = df.groupby('Gender')['Age'].cumsum()

# Output the updated DataFrame
print("DataFrame with Cumulative Sum of 'Age' for each Gender:")
df



# Problem: Create a pivot table showing the average and maximum 'Age' for each Gender and City.

# Create the pivot table
pivot = df.pivot_table(
    values='Age',
    index='Gender',
    columns='City',
    aggfunc=['mean', 'max'],
    fill_value=0
)

# Output the pivot table
print("Pivot table with average and maximum 'Age':")
pivot



# Problem: Calculate the percentage distribution of each Gender in the DataFrame.

# Calculate the percentage distribution
gender_percentage = (df['Gender'].value_counts(normalize=True) * 100).round(2)

# Output the result
print("Percentage distribution of each Gender:")
print(gender_percentage)



# Problem: Detect and replace outliers in the 'Age' column using the IQR method.
import numpy as np

# Calculate the IQR (Interquartile Range)
Q1 = df['Age'].quantile(0.25)
Q3 = df['Age'].quantile(0.75)
IQR = Q3 - Q1

# Define the lower and upper bounds for outliers
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Replace outliers with the median Age
median_age = df['Age'].median()
df['Age_Cleaned'] = df['Age'].apply(lambda x: median_age if x < lower_bound or x > upper_bound else x)

# Output the DataFrame with cleaned Age column
print("DataFrame after handling outliers in the 'Age' column:")
print(df)



# Problem: Calculate a 3-period rolling average of the 'Age' column.

import pandas as pd

# Create the initial DataFrame
data = {
    'Name': ['John', 'Alice', 'Bob', 'Eve', 'Michael', 'Sophia'],
    'Age': [25, 30, 22, 27, 35, 29],
    'City': ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Seattle', 'Austin'],
    'Gender': ['Male', 'Female', 'Male', 'Female', 'Male', 'Female']
}

df = pd.DataFrame(data)

# Calculate the 3-period rolling average of 'Age'
df['Rolling_Average_Age'] = df['Age'].rolling(window=3).mean()

# Output the updated DataFrame
print("DataFrame with 3-period rolling average of 'Age':")
print(df)



# Problem: Add a new column 'Age_Squared' by squaring the values in the 'Age' column.

# Define a custom function to square a number
def square(x):
    return x ** 2

# Apply the function to the 'Age' column
df['Age_Squared'] = df['Age'].apply(square)

# Output the updated DataFrame
print("DataFrame with 'Age_Squared' column:")
print(df)



# Problem: Replace all 'Age' values greater than 30 with the string 'Senior'.

# Replace values in 'Age' column based on a condition
df['Age_Updated'] = df['Age'].apply(lambda x: 'Senior' if x > 30 else x)

# Output the updated DataFrame
print("DataFrame with 'Age' values replaced based on a condition:")
print(df)



# Problem: Count the number of unique cities in the DataFrame.

# Count unique cities
unique_cities_count = df['City'].nunique()

# Output the result
print(f"Number of unique cities: {unique_cities_count}")



# Problem: Create a new DataFrame with the sum of 'Age' for each Gender group.

# Group by Gender and sum the 'Age' column
gender_age_sum = df.groupby('Gender')['Age'].sum().reset_index()

# Output the new DataFrame
print("New DataFrame with sum of 'Age' for each Gender:")
print(gender_age_sum)



# Problem: Rank the rows within each Gender group by 'Age', assigning 1 to the oldest.

# Rank within each Gender group
df['Age_Rank'] = df.groupby('Gender')['Age'].rank(ascending=False)

# Output the updated DataFrame
print("DataFrame with Age rank within Gender groups:")
print(df)



# Problem: Calculate the percent change in 'Age' for consecutive rows.

# Calculate percent change in 'Age'
df['Age_Percent_Change'] = df['Age'].pct_change() * 100

# Output the updated DataFrame
print("DataFrame with percent change in 'Age':")
print(df)



# Problem: Convert a string column to datetime format and extract year, month, and day.

import pandas as pd

# Create a DataFrame with a date column in string format
data = {'Name': ['John', 'Alice', 'Bob', 'Eve'],
        'Join_Date': ['2023-01-15', '2021-06-10', '2022-03-05', '2020-11-20']}

df = pd.DataFrame(data)

# Convert the 'Join_Date' column to datetime format
df['Join_Date'] = pd.to_datetime(df['Join_Date'])

# Extract year, month, and day from the 'Join_Date' column
df['Year'] = df['Join_Date'].dt.year
df['Month'] = df['Join_Date'].dt.month
df['Day'] = df['Join_Date'].dt.day

# Output the updated DataFrame
print("DataFrame with year, month, and day extracted:")
print(df)



# Problem: Find and remove duplicate rows in the DataFrame.

# Create a DataFrame with duplicate rows
data = {'Name': ['John', 'Alice', 'Bob', 'Alice'],
        'Age': [25, 30, 22, 30],
        'City': ['New York', 'Los Angeles', 'Chicago', 'Los Angeles']}

df = pd.DataFrame(data)

# Find duplicate rows
duplicates = df[df.duplicated()]

# Remove duplicate rows
df_cleaned = df.drop_duplicates()

# Output the results
print("Duplicate rows:")
print(duplicates)
print("\nDataFrame after removing duplicates:")
print(df_cleaned)



# Problem: Merge two DataFrames on multiple keys (Name and City).

# Create two DataFrames
df1 = pd.DataFrame({'Name': ['John', 'Alice', 'Bob'],
                    'City': ['New York', 'Los Angeles', 'Chicago'],
                    'Age': [25, 30, 22]})

df2 = pd.DataFrame({'Name': ['John', 'Alice', 'Bob'],
                    'City': ['New York', 'Los Angeles', 'Seattle'],
                    'Salary': [70000, 80000, 60000]})

# Merge on multiple keys
merged_df = pd.merge(df1, df2, on=['Name', 'City'], how='inner')

# Output the merged DataFrame
print("Merged DataFrame:")
print(merged_df)



# Problem: Group by Gender and calculate custom aggregations: average Age and count of rows.

# Create the initial DataFrame
data = {'Name': ['John', 'Alice', 'Bob', 'Eve', 'Michael', 'Sophia'],
        'Age': [25, 30, 22, 27, 35, 29],
        'Gender': ['Male', 'Female', 'Male', 'Female', 'Male', 'Female']}

df = pd.DataFrame(data)

# Group by Gender and apply custom aggregations
agg_df = df.groupby('Gender').agg(
    Avg_Age=('Age', 'mean'),
    Count=('Name', 'size')
).reset_index()

# Output the aggregated DataFrame
print("Aggregated DataFrame with custom functions:")
print(agg_df)



# Problem: Reshape the DataFrame using the melt function to make it long-form.

# Create a DataFrame
data = {'Name': ['John', 'Alice', 'Bob'],
        'Math': [85, 90, 78],
        'Science': [92, 88, 80]}

df = pd.DataFrame(data)

# Melt the DataFrame
melted_df = pd.melt(df, id_vars=['Name'], var_name='Subject', value_name='Score')

# Output the melted DataFrame
print("Melted DataFrame:")
print(melted_df)



# Problem: Pivot the melted DataFrame back to its original wide format.

# Pivot the melted DataFrame
pivoted_df = melted_df.pivot(index='Name', columns='Subject', values='Score').reset_index()

# Output the pivoted DataFrame
print("Pivoted DataFrame:")
print(pivoted_df)



# Problem: Calculate the correlation matrix for numeric columns in the DataFrame.

# Create a DataFrame
data = {'Math': [85, 90, 78, 88],
        'Science': [92, 88, 80, 86],
        'English': [87, 84, 83, 90]}

df = pd.DataFrame(data)

# Calculate the correlation matrix
correlation_matrix = df.corr()

# Output the correlation matrix
print("Correlation matrix:")
print(correlation_matrix)






# Problem: Extract the domain names from email addresses in a column.

import pandas as pd

# Create a DataFrame with email addresses
data = {'Email': ['john.doe@example.com', 'alice123@company.org', 'bob.smith@edu.net']}
df = pd.DataFrame(data)

# Extract domain names using regex
df['Domain'] = df['Email'].str.extract(r'@([\w.-]+)')

# Output the updated DataFrame
print("Extracted domain names from email addresses:")
print(df)



# Problem: Filter rows where the 'Email' column contains email addresses ending with '.com'.

# Filter rows using regex
filtered_df = df[df['Email'].str.contains(r'\.com$')]

# Output the filtered DataFrame
print("Filtered rows with '.com' email addresses:")
print(filtered_df)



# Problem: Validate phone numbers in a column (format: (XXX) XXX-XXXX).

# Create a DataFrame with phone numbers
data = {'Phone': ['(123) 456-7890', '123-456-7890', '(987) 654-3210']}
df = pd.DataFrame(data)

# Validate phone numbers using regex
df['Valid_Phone'] = df['Phone'].str.match(r'^\(\d{3}\) \d{3}-\d{4}$')

# Output the updated DataFrame
print("Validation of phone numbers:")
print(df)



# Problem: Extract all numbers from a column of strings.

# Create a DataFrame with mixed strings
data = {'Text': ['Order #12345', 'Item ID: 67890', 'Ref: ABC-9876']}
df = pd.DataFrame(data)

# Extract numbers using regex
df['Numbers'] = df['Text'].str.extract(r'(\d+)')

# Output the updated DataFrame
print("Extracted numbers from strings:")
print(df)



# Problem: Replace special characters in a column with underscores.

# Replace special characters using regex
df['Cleaned_Text'] = df['Text'].str.replace(r'[^a-zA-Z0-9]', '_', regex=True)

# Output the updated DataFrame
print("Replaced special characters with underscores:")
print(df)



# Problem: Extract the first word from a column of strings.

# Extract the first word using regex
df['First_Word'] = df['Text'].str.extract(r'^(\w+)')

# Output the updated DataFrame
print("Extracted the first word from strings:")
print(df)



# Problem: Identify rows where the 'Text' column contains a specific pattern (e.g., words starting with 'O').

# Find rows with words starting with 'O'
df['Starts_With_O'] = df['Text'].str.contains(r'\bO\w*')

# Output the updated DataFrame
print("Rows where 'Text' contains words starting with 'O':")
print(df)



# Problem: Extract both letters and numbers from a column into separate columns.

# Extract letters and numbers using regex
df[['Letters', 'Digits']] = df['Text'].str.extract(r'([A-Za-z]+).*?(\d+)')

# Output the updated DataFrame
print("Extracted letters and numbers into separate columns:")
print(df)



# Problem: Split strings in the 'Text' column into multiple parts based on spaces or special characters.

# Split strings using regex
df['Split_Text'] = df['Text'].str.split(r'[^\w]+')

# Output the updated DataFrame
print("Split strings into multiple parts:")
print(df)



# Problem: Identify rows where the 'Text' column contains the word 'Order'.

# Find rows containing the specific word 'Order'
df['Contains_Order'] = df['Text'].str.contains(r'\bOrder\b', regex=True)

# Output the updated DataFrame
print("Rows where 'Text' contains the word 'Order':")
print(df)



# Problem: Extract all words with exactly 5 characters from a column.

import pandas as pd

# Create a DataFrame
data = {'Text': ['Order ID 12345', 'This is a test', 'Words like hello']}
df = pd.DataFrame(data)

# Extract words with exactly 5 characters
df['Five_Char_Words'] = df['Text'].str.findall(r'\b\w{5}\b')

# Output the updated DataFrame
print("Extracted words with exactly 5 characters:")
print(df)



# Problem: Replace all occurrences of numbers with the string '<NUMBER>'.

# Replace numbers with the string '<NUMBER>'
df['Replaced_Text'] = df['Text'].str.replace(r'\d+', '<NUMBER>', regex=True)

# Output the updated DataFrame
print("Replaced numbers with '<NUMBER>':")
print(df)



# Problem: Identify rows where the 'Text' column contains only alphabetic characters.

# Check if the column contains only alphabetic characters
df['Only_Alphabets'] = df['Text'].str.match(r'^[a-zA-Z\s]+$')

# Output the updated DataFrame
print("Rows where 'Text' contains only alphabets:")
print(df)



# Problem: Extract substrings that are between square brackets (e.g., [content]).

# Add sample data with brackets
data = {'Text': ['This [is] a test', 'Find [words] here', 'No brackets']}
df = pd.DataFrame(data)

# Extract substrings between square brackets
df['Bracket_Content'] = df['Text'].str.extract(r'\[(.*?)\]')

# Output the updated DataFrame
print("Extracted substrings between brackets:")
print(df)



# Problem: Count how many times a specific word (e.g., 'test') appears in each row.

# Count occurrences of the word 'test'
df['Test_Count'] = df['Text'].str.count(r'\btest\b')

# Output the updated DataFrame
print("Count of the word 'test' in each row:")
print(df)



# Problem: Extract all words starting with the letter 'W'.

# Extract words starting with 'W'
df['Words_Starting_With_W'] = df['Text'].str.findall(r'\bW\w*')

# Output the updated DataFrame
print("Words starting with 'W':")
print(df)



# Problem: Split the text into a list of words, ignoring punctuation.

# Split text into words ignoring punctuation
df['Split_Words'] = df['Text'].str.split(r'[^\w]+')

# Output the updated DataFrame
print("Split text into words ignoring punctuation:")
print(df)



# Problem: Extract all patterns that look like hashtags (e.g., #example).

# Add sample data with hashtags
data = {'Text': ['This is #fun', '#Python is #awesome', 'No hashtags here']}
df = pd.DataFrame(data)

# Extract all hashtags
df['Hashtags'] = df['Text'].str.findall(r'#\w+')

# Output the updated DataFrame
print("Extracted hashtags from text:")
print(df)



# Problem: Replace all hashtags and mentions (e.g., @user) with placeholders.

# Replace hashtags with <HASHTAG> and mentions with <MENTION>
df['Replaced_Text'] = df['Text'].str.replace(r'#\w+', '<HASHTAG>', regex=True).str.replace(r'@\w+', '<MENTION>', regex=True)

# Output the updated DataFrame
print("Replaced hashtags and mentions with placeholders:")
print(df)



# Problem: Extract email usernames and domains into separate columns using named groups.

# Add sample email data
data = {'Email': ['john.doe@example.com', 'alice123@company.org', 'test.user@domain.net']}
df = pd.DataFrame(data)

# Extract email parts using named groups
df[['Username', 'Domain']] = df['Email'].str.extract(r'(?P<Username>[\w.]+)@(?P<Domain>[\w.-]+)')

# Output the updated DataFrame
print("Extracted email usernames and domains:")
print(df)



# Problem: Highlight specific words (e.g., 'Python' or 'fun') in a column by wrapping them with `**`.

import pandas as pd

# Create a DataFrame
data = {'Text': ['Learning Python is fun', 'Python is amazing', 'Regex is powerful']}
df = pd.DataFrame(data)

# Highlight the words 'Python' or 'fun'
df['Highlighted_Text'] = df['Text'].str.replace(r'\b(Python|fun)\b', r'**\1**', regex=True)

# Output the updated DataFrame
print("Highlighted specific words:")
print(df)



# Problem: Extract all email addresses from a column containing text.

# Add sample data with embedded emails
data = {'Text': ['Contact us at support@example.com or admin@domain.net.',
                 'Send an email to test.user@service.org for help.',
                 'No email here.']}
df = pd.DataFrame(data)

# Extract all email addresses
df['Emails'] = df['Text'].str.findall(r'[\w.]+@[\w.-]+\.\w+')

# Output the updated DataFrame
print("Extracted email addresses:")
print(df)



# Problem: Extract sentences that contain the word 'email'.

# Add sample data with multiple sentences
data = {'Text': ['Send an email to support@example.com.',
                 'This is a test sentence.',
                 'Emails are important for communication.']}
df = pd.DataFrame(data)

# Extract sentences containing the word 'email'
df['Email_Sentences'] = df['Text'].str.extract(r'([^\.]*\bemail\b[^\.]*)', expand=False)

# Output the updated DataFrame
print("Extracted sentences containing 'email':")
print(df)



# Problem: Extract dates in formats like 'YYYY-MM-DD', 'MM/DD/YYYY', or 'DD.MM.YYYY'.

# Add sample data with mixed date formats
data = {'Text': ['Event on 2023-01-15.', 'Deadline: 02/20/2023.', 'Date: 15.03.2023.', 'No date here.']}
df = pd.DataFrame(data)

# Extract dates
df['Dates'] = df['Text'].str.extract(r'(\b\d{4}-\d{2}-\d{2}\b|\b\d{2}/\d{2}/\d{4}\b|\b\d{2}\.\d{2}\.\d{4}\b)')

# Output the updated DataFrame
print("Extracted dates:")
print(df)



# Problem: Mask sensitive data like email addresses or phone numbers in a column.

# Add sample data with sensitive information
data = {'Text': ['Contact: john.doe@example.com, Phone: (123) 456-7890.',
                 'Email: alice123@domain.org.', 
                 'No sensitive data here.']}
df = pd.DataFrame(data)

# Mask sensitive data
df['Masked_Text'] = df['Text'].str.replace(r'[\w.]+@[\w.-]+\.\w+', '[EMAIL]', regex=True) \
                              .str.replace(r'\(\d{3}\) \d{3}-\d{4}', '[PHONE]', regex=True)

# Output the updated DataFrame
print("Masked sensitive data:")
print(df)



# Problem: Extract the initials from a full name in a column.

# Add sample data with names
data = {'Name': ['John Doe', 'Alice B. Wonderland', 'Charlie']}
df = pd.DataFrame(data)

# Extract initials
df['Initials'] = df['Name'].str.extractall(r'\b(\w)') \
                           .groupby(level=0)[0].apply(''.join)

# Output the updated DataFrame
print("Extracted initials:")
print(df)



# Problem: Identify all non-alphanumeric characters in a column.

# Add sample data with mixed characters
data = {'Text': ['Hello, World!', 'Regex is #1!', 'No_special*characters']}
df = pd.DataFrame(data)

# Find non-alphanumeric characters
df['Non_Alphanumeric'] = df['Text'].str.findall(r'[^\w\s]')

# Output the updated DataFrame
print("Non-alphanumeric characters found:")
print(df)



# Problem: Extract consecutive sequences of digits (e.g., 12345).

# Add sample data with numbers
data = {'Text': ['Order12345', 'ID 67890 and 1234', 'No numbers']}
df = pd.DataFrame(data)

# Extract sequences of digits
df['Numbers'] = df['Text'].str.findall(r'\d+')

# Output the updated DataFrame
print("Extracted sequences of digits:")
print(df)



# Problem: Validate URLs in a column.

# Add sample data with URLs
data = {'Text': ['https://example.com', 'www.google.com', 'invalid-url', 'http://test.org']}
df = pd.DataFrame(data)

# Validate URLs
df['Valid_URL'] = df['Text'].str.match(r'^https?://[^\s/$.?#].[^\s]*$')

# Output the updated DataFrame
print("Validation of URLs:")
print(df)



# Problem: Extract hashtags but ensure they are standalone words (not part of a longer string).

import pandas as pd

# Create a DataFrame with sentences containing hashtags
data = {'Text': ['#fun #learning is great', 'Code with #Python3 is fun', 'This is #coolstuff!','#cool']}
df = pd.DataFrame(data)

# Extract standalone hashtags
df['Standalone_Hashtags'] = df['Text'].str.findall(r'#\w+')

# Output the updated DataFrame
print("Extracted standalone hashtags:")
df




